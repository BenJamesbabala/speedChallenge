{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import pandas as pd\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network Architecture (DeepVO AlexNetLike)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Dense, Activation, Flatten, merge\n",
    "from keras.models import Model\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.layers.convolutional import Convolution2D\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "\n",
    "tf.python.control_flow_ops = tf\n",
    "\n",
    "# image_1 = Input(shape = (3, 256, 256), name='image1')\n",
    "# image_2 = Input(shape = (3, 256, 256), name='image2')\n",
    "\n",
    "# N_img_height = 256\n",
    "# N_img_width = 256\n",
    "# N_img_channels = 3\n",
    "\n",
    "# inputShape = (N_img_height, N_img_width, N_img_channels)\n",
    "def DeepVo():\n",
    "    # TODO: Maybe add zeroPadding2D(1, 1) after each layer\n",
    "    # TODO: Maybe take out input_shape = inputShape from first conv layer\n",
    "    \n",
    "    # Loading inputs: \n",
    "    image_1 = Input(shape = (256, 256, 3), name='image1')\n",
    "    image_2 = Input(shape = (256, 256, 3), name='image2')\n",
    "    \n",
    "    ######## LAYER 1 ####################\n",
    "    # Convolution Layer 1: Channel 1\n",
    "    x1 = Convolution2D(48, 11, 11, subsample=(4, 4), \n",
    "                      init = 'he_normal', \n",
    "                      border_mode = 'valid', \n",
    "                      activation = 'relu',\n",
    "#                       input_shape = inputShape,  # may not be necessary\n",
    "                      name = 'conv_1_x')(image_1)\n",
    "    \n",
    "    # Convolution Layer 1: Channel 2\n",
    "    y1 = Convolution2D(48, 11, 11, subsample=(4, 4), \n",
    "                      init = 'he_normal', \n",
    "                      border_mode = 'valid', \n",
    "                      activation = 'relu',\n",
    "#                       input_shape = inputShape,  # may not be necessary\n",
    "                      name = 'conv_1_y')(image_2)\n",
    "    \n",
    "    # Max Pooling Layer 1: Channel 1\n",
    "    x1 = MaxPooling2D((3, 3), strides = (2, 2))(x1)\n",
    "    \n",
    "    # Max Pooling Layer 1: Channel 2\n",
    "    y1 = MaxPooling2D((3, 3), strides = (2, 2))(y1)\n",
    "    ######## END OF LAYER 1 ####################\n",
    "\n",
    "    ######## LAYER 2####################\n",
    "    # Convolution Layer 2: Channel 1\n",
    "    x1 = Convolution2D(128, 5, 5, subsample = (1, 1), \n",
    "                      init = 'he_normal', \n",
    "                      border_mode = 'valid', \n",
    "                      activation = 'relu', \n",
    "                      name = 'conv_2_x')(x1)\n",
    "    \n",
    "    # Convolution Layer 2: Channel 2\n",
    "    y1 = Convolution2D(128, 5, 5, subsample = (1, 1), \n",
    "                      init = 'he_normal', \n",
    "                      border_mode = 'valid', \n",
    "                      activation = 'relu', \n",
    "                      name = 'conv_2_y')(y1)\n",
    "    \n",
    "    # Max Pooling Layer 1: Channel 1\n",
    "    x1 = MaxPooling2D((3, 3), strides = (2, 2))(x1)\n",
    "    \n",
    "    # Max Pooling Layer 1: Channel 2\n",
    "    y1 = MaxPooling2D((3, 3), strides = (2, 2))(y1)\n",
    "    \n",
    "    ####### LAYER 3 ###################\n",
    "    # Convolution Layer 3: Channel 1\n",
    "    x1 = Convolution2D(192, 3, 3, subsample = (1, 1), \n",
    "                  init = 'he_normal', \n",
    "                  border_mode = 'valid', \n",
    "                  activation = 'relu', \n",
    "                  name = 'conv_3_x')(x1)\n",
    "\n",
    "    # Convolution Layer 3: Channel 2\n",
    "    y1 = Convolution2D(192, 3, 3, subsample = (1, 1), \n",
    "                  init = 'he_normal', \n",
    "                  border_mode = 'valid', \n",
    "                  activation = 'relu', \n",
    "                  name = 'conv_3_y')(y1)\n",
    "    \n",
    "    ####### LAYER 4 ###################\n",
    "    # Convolution Layer 4: Channel 1\n",
    "    x1 = Convolution2D(192, 3, 3, subsample = (1, 1), \n",
    "                  init = 'he_normal', \n",
    "                  border_mode = 'valid', \n",
    "                  activation = 'relu', \n",
    "                  name = 'conv_4_x')(x1)\n",
    "\n",
    "    # Convolution Layer 4: Channel 2\n",
    "    y1 = Convolution2D(192, 3, 3, subsample = (1, 1), \n",
    "                  init = 'he_normal', \n",
    "                  border_mode = 'valid', \n",
    "                  activation = 'relu', \n",
    "                  name = 'conv_4_y')(y1)\n",
    "    \n",
    "    ####### LAYER 5 ###################\n",
    "    # Convolution Layer 5: Channel 1\n",
    "    x1 = Convolution2D(192, 3, 3, subsample = (1, 1), \n",
    "                  init = 'he_normal', \n",
    "                  border_mode = 'valid', \n",
    "                  activation = 'relu', \n",
    "                  name = 'conv_5_x')(x1)\n",
    "\n",
    "    # Convolution Layer 5: Channel 2\n",
    "    y1 = Convolution2D(192, 3, 3, subsample = (1, 1), \n",
    "                  init = 'he_normal', \n",
    "                  border_mode = 'valid', \n",
    "                  activation = 'relu', \n",
    "                  name = 'conv_5_y')(y1)\n",
    "    \n",
    "    ####### Flatten ###########\n",
    "    x2 = Flatten(name='flatten_x1')(x1)\n",
    "    y2 = Flatten(name='flatten_y1')(y1)\n",
    "    \n",
    "    # TODO: Maybe add a relu after these layers\n",
    "    ###### Fully Connected 1 using Xaviers algorithm (glorot normal) ########\n",
    "    x3 = Dense(2048, activation = 'relu', init = 'glorot_normal', name = 'fc1_x2')(x2)\n",
    "    y3 = Dense(2048, activation = 'relu', init = 'glorot_normal', name = 'fc1_y2')(y2)\n",
    "    \n",
    "    ###### Fully Connected 2 ########\n",
    "    x3 = Dense(2048, activation = 'relu', init = 'glorot_normal', name = 'fc2_x2')(x2)\n",
    "    y3 = Dense(2048, activation = 'relu', init = 'glorot_normal', name = 'fc2_y2')(y2)\n",
    "    \n",
    "    ##### Merge ####### \n",
    "    # TODO: Try concatenation instead of merging\n",
    "    print('x3 shape: ', x3.get_shape())\n",
    "    m3 = merge([x3, y3], mode='concat', concat_axis = 1, name = 'merge_x3y3')\n",
    "    \n",
    "    print('m3 shape: ', m3.get_shape())\n",
    "    #### Flatten #####\n",
    "#     flat3 = Flatten(name = 'flatten_merge')(m3)\n",
    "    \n",
    "    #### Fully connected 3 ######\n",
    "    fc3 = Dense(4096, activation = 'relu', init = 'glorot_normal', name = 'fc3')(m3)\n",
    "    \n",
    "    ### Fully connected 4 ######\n",
    "    fc4 = Dense(1024, activation = 'relu', init = 'glorot_normal', name = 'fc4')(fc3)\n",
    "    \n",
    "    ### Fully connected 5 ######\n",
    "    prediction = Dense(1, name = 'output')(fc4)\n",
    "    \n",
    "    model = Model(input = [image_1, image_2], output = [prediction, prediction])\n",
    "    \n",
    "    adam = Adam(lr=1e-4, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "    model.compile(optimizer = adam, loss = 'mse')\n",
    "    \n",
    "    return model\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manually create testing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = np.asarray([img_1, img_2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img1 = np.asarray(img_1, dtype=np.uint8)\n",
    "img2 = np.asarray(img_2, dtype=np.uint8)\n",
    "X_train = np.asarray([img1, img2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train = [[14.136534929275513, 5.7756648244489179], [14.195453882217407, 5.751016049309901]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_training_data(image_data, label):\n",
    "    # image_data array with two images\n",
    "    # label is the ground truth tuple [time, speed]\n",
    "    img1 = image_data[0]\n",
    "    img2 = image_data[1]\n",
    "    s1 = label[0][1]\n",
    "    s2 = label[1][1]\n",
    "    ds = abs(s2 - s1)\n",
    "    print('img1: ', img1.shape)\n",
    "    print('img2: ', img2.shape)\n",
    "    print('ds: ', ds)\n",
    "    \n",
    "    \n",
    "    yield (img1, img2, ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x3 shape:  (?, 2048)\n",
      "m3 shape:  (?, 4096)\n"
     ]
    }
   ],
   "source": [
    "model = DeepVo()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BATCH = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img1: Epoch 1/1 (204, 204, 3)\n",
      "\n",
      "img2:  (256, 256, 3)\n",
      "ds:  0.024648775139016976\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-13:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jj/anaconda2/envs/python3/lib/python3.5/threading.py\", line 914, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/jj/anaconda2/envs/python3/lib/python3.5/threading.py\", line 862, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/jj/anaconda2/envs/python3/lib/python3.5/site-packages/keras/engine/training.py\", line 425, in data_generator_task\n",
      "    generator_output = next(generator)\n",
      "StopIteration\n",
      "\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "output of generator should be a tuple (x, y, sample_weight) or (x, y). Found: None",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-a25c77a1c95f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtrain_generator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_training_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_generator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msamples_per_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/jj/anaconda2/envs/python3/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, samples_per_epoch, nb_epoch, verbose, callbacks, validation_data, nb_val_samples, class_weight, max_q_size, nb_worker, pickle_safe)\u001b[0m\n\u001b[1;32m   1415\u001b[0m                     raise Exception('output of generator should be a tuple '\n\u001b[1;32m   1416\u001b[0m                                     \u001b[0;34m'(x, y, sample_weight) '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1417\u001b[0;31m                                     'or (x, y). Found: ' + str(generator_output))\n\u001b[0m\u001b[1;32m   1418\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator_output\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1419\u001b[0m                     \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerator_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mException\u001b[0m: output of generator should be a tuple (x, y, sample_weight) or (x, y). Found: None"
     ]
    }
   ],
   "source": [
    "train_generator = generate_training_data(X_train, y_train)\n",
    "history = model.fit_generator(train_generator, samples_per_epoch = 1, nb_epoch = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "modelx = DeepVo()\n",
    "print('model created!')\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:python3]",
   "language": "python",
   "name": "conda-env-python3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
